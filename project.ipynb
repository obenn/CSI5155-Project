{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b74de16614daa0846ddfaf5c205b09a61d1fef6a850ce9d5a0bef4ebf69fbd07"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import permutations, combinations\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_confusion_matrix, plot_roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from pprint import pprint\n",
    "from scipy.stats import ttest_rel\n",
    "from semisupervised.StackedAutoEncoderSSL import StackedAutoEncoderClassifier\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0            2278392      8222157        Caucasian  Female   [0-10)    NaN   \n",
       "1             149190     55629189        Caucasian  Female  [10-20)    NaN   \n",
       "2              64410     86047875  AfricanAmerican  Female  [20-30)    NaN   \n",
       "3             500364     82442376        Caucasian    Male  [30-40)    NaN   \n",
       "4              16680     42519267        Caucasian    Male  [40-50)    NaN   \n",
       "...              ...          ...              ...     ...      ...    ...   \n",
       "101761     443847548    100162476  AfricanAmerican    Male  [70-80)    NaN   \n",
       "101762     443847782     74694222  AfricanAmerican  Female  [80-90)    NaN   \n",
       "101763     443854148     41088789        Caucasian    Male  [70-80)    NaN   \n",
       "101764     443857166     31693671        Caucasian  Female  [80-90)    NaN   \n",
       "101765     443867222    175429310        Caucasian    Male  [70-80)    NaN   \n",
       "\n",
       "        admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                       6                        25                    1   \n",
       "1                       1                         1                    7   \n",
       "2                       1                         1                    7   \n",
       "3                       1                         1                    7   \n",
       "4                       1                         1                    7   \n",
       "...                   ...                       ...                  ...   \n",
       "101761                  1                         3                    7   \n",
       "101762                  1                         4                    5   \n",
       "101763                  1                         1                    7   \n",
       "101764                  2                         3                    7   \n",
       "101765                  1                         1                    7   \n",
       "\n",
       "        time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                      1  ...          No      No                   No   \n",
       "1                      3  ...          No      Up                   No   \n",
       "2                      2  ...          No      No                   No   \n",
       "3                      2  ...          No      Up                   No   \n",
       "4                      1  ...          No  Steady                   No   \n",
       "...                  ...  ...         ...     ...                  ...   \n",
       "101761                 3  ...          No    Down                   No   \n",
       "101762                 5  ...          No  Steady                   No   \n",
       "101763                 1  ...          No    Down                   No   \n",
       "101764                10  ...          No      Up                   No   \n",
       "101765                 6  ...          No      No                   No   \n",
       "\n",
       "        glipizide-metformin  glimepiride-pioglitazone  \\\n",
       "0                        No                        No   \n",
       "1                        No                        No   \n",
       "2                        No                        No   \n",
       "3                        No                        No   \n",
       "4                        No                        No   \n",
       "...                     ...                       ...   \n",
       "101761                   No                        No   \n",
       "101762                   No                        No   \n",
       "101763                   No                        No   \n",
       "101764                   No                        No   \n",
       "101765                   No                        No   \n",
       "\n",
       "        metformin-rosiglitazone  metformin-pioglitazone  change diabetesMed  \\\n",
       "0                            No                      No      No          No   \n",
       "1                            No                      No      Ch         Yes   \n",
       "2                            No                      No      No         Yes   \n",
       "3                            No                      No      Ch         Yes   \n",
       "4                            No                      No      Ch         Yes   \n",
       "...                         ...                     ...     ...         ...   \n",
       "101761                       No                      No      Ch         Yes   \n",
       "101762                       No                      No      No         Yes   \n",
       "101763                       No                      No      Ch         Yes   \n",
       "101764                       No                      No      Ch         Yes   \n",
       "101765                       No                      No      No          No   \n",
       "\n",
       "       readmitted  \n",
       "0              NO  \n",
       "1             >30  \n",
       "2              NO  \n",
       "3              NO  \n",
       "4              NO  \n",
       "...           ...  \n",
       "101761        >30  \n",
       "101762         NO  \n",
       "101763         NO  \n",
       "101764         NO  \n",
       "101765         NO  \n",
       "\n",
       "[101766 rows x 50 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encounter_id</th>\n      <th>patient_nbr</th>\n      <th>race</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>weight</th>\n      <th>admission_type_id</th>\n      <th>discharge_disposition_id</th>\n      <th>admission_source_id</th>\n      <th>time_in_hospital</th>\n      <th>...</th>\n      <th>citoglipton</th>\n      <th>insulin</th>\n      <th>glyburide-metformin</th>\n      <th>glipizide-metformin</th>\n      <th>glimepiride-pioglitazone</th>\n      <th>metformin-rosiglitazone</th>\n      <th>metformin-pioglitazone</th>\n      <th>change</th>\n      <th>diabetesMed</th>\n      <th>readmitted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2278392</td>\n      <td>8222157</td>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>[0-10)</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>25</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>149190</td>\n      <td>55629189</td>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>[10-20)</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Up</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Ch</td>\n      <td>Yes</td>\n      <td>&gt;30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>64410</td>\n      <td>86047875</td>\n      <td>AfricanAmerican</td>\n      <td>Female</td>\n      <td>[20-30)</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>2</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500364</td>\n      <td>82442376</td>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>[30-40)</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>2</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Up</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Ch</td>\n      <td>Yes</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16680</td>\n      <td>42519267</td>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>[40-50)</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Steady</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Ch</td>\n      <td>Yes</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>101761</th>\n      <td>443847548</td>\n      <td>100162476</td>\n      <td>AfricanAmerican</td>\n      <td>Male</td>\n      <td>[70-80)</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>3</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Down</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Ch</td>\n      <td>Yes</td>\n      <td>&gt;30</td>\n    </tr>\n    <tr>\n      <th>101762</th>\n      <td>443847782</td>\n      <td>74694222</td>\n      <td>AfricanAmerican</td>\n      <td>Female</td>\n      <td>[80-90)</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Steady</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>101763</th>\n      <td>443854148</td>\n      <td>41088789</td>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>[70-80)</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Down</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Ch</td>\n      <td>Yes</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>101764</th>\n      <td>443857166</td>\n      <td>31693671</td>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>[80-90)</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>3</td>\n      <td>7</td>\n      <td>10</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Up</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Ch</td>\n      <td>Yes</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>101765</th>\n      <td>443867222</td>\n      <td>175429310</td>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>[70-80)</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>6</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>NO</td>\n    </tr>\n  </tbody>\n</table>\n<p>101766 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('diabetic_data.csv', na_values=['?'], low_memory=False)\n",
    "df"
   ]
  },
  {
   "source": [
    "## Part A: Feature engineering, supervised learning and evaluation of results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's look at the features in the dataset referring to their descriptions in the paper, we'll decide if any transformations need to be done."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_mapping = lambda x : {v: i for i, v in enumerate(x)}\n",
    "categorical_mappings = []\n",
    "onehot_columns = []"
   ]
  },
  {
   "source": [
    "### Encounter Id (encounter_id)\n",
    "\n",
    "Unique identifier of an encounter\n",
    "\n",
    "We will drop this column as it does not give us any actual qualitative information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('encounter_id', axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Patient number (patient_nbr)\n",
    "\n",
    "Unique identifier of a patient\n",
    "\n",
    "We will drop this column as it does not give us any actual qualitative information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('patient_nbr', axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Race (race)\n",
    "\n",
    "Values: Caucasian, Asian, African American, Hispanic, and other\n",
    "\n",
    "This is a categorical variable without ordering. There appear to be 2% missing values, we will assign them to an Unknown category."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Caucasian          76099\n",
       "AfricanAmerican    19210\n",
       "Unknown             2273\n",
       "Hispanic            2037\n",
       "Other               1506\n",
       "Asian                641\n",
       "Name: race, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "onehot_columns.append('race')\n",
    "df['race'].fillna('Unknown', inplace=True)\n",
    "df['race'].value_counts(dropna=False)"
   ]
  },
  {
   "source": [
    "#### Gender (gender)\n",
    "\n",
    "Values, Male/Female, Unknown/Invalid\n",
    "\n",
    "We will encode this variable in a -1, 0, 1 fashion\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Female             54708\n",
       "Male               47055\n",
       "Unknown/Invalid        3\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "categorical_mappings.append({\n",
    "    \"col\": \"gender\",\n",
    "    \"mapping\": {\n",
    "        \"Male\": 1,\n",
    "        \"Female\": -1,\n",
    "        \"Unknown/Invalid\": 0,\n",
    "    }\n",
    "})\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "source": [
    "### Age (age)\n",
    "\n",
    "This is an ordinal variable, we will order them accoridng to the age ranges."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[70-80)     26068\n",
       "[60-70)     22483\n",
       "[50-60)     17256\n",
       "[80-90)     17197\n",
       "[40-50)      9685\n",
       "[30-40)      3775\n",
       "[90-100)     2793\n",
       "[20-30)      1657\n",
       "[10-20)       691\n",
       "[0-10)        161\n",
       "Name: age, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "categorical_mappings.append({\n",
    "    \"col\": \"age\",\n",
    "    \"mapping\": ordered_mapping([f\"[{i}-{i+10})\" for i in range(0, 100, 10)]),\n",
    "})\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "source": [
    "### Weight (weight)\n",
    "\n",
    "There look to be 98% missing values according to the paper. Let's verify and drop the column if this is the case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NaN          98569\n",
       "[75-100)      1336\n",
       "[50-75)        897\n",
       "[100-125)      625\n",
       "[125-150)      145\n",
       "[25-50)         97\n",
       "[0-25)          48\n",
       "[150-175)       35\n",
       "[175-200)       11\n",
       ">200             3\n",
       "Name: weight, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df['weight'].value_counts(dropna=False)"
   ]
  },
  {
   "source": [
    "Because of this disproportionality we will drop the column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('weight', axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Admission type (admission_type_id)\n",
    "\n",
    "Integer identifier corresponding to 9 distinct values, for example, emergency, urgent, elective, newborn, and not available\n",
    "\n",
    "There is no obvious ordering for these so for this reason we will need to encode this as a categorical variable using one-hot encoding.\n",
    "\n",
    "We note that categories \"NULL\", \"not available\" and \"not mapped\" are all effectively unknown and we therefore combine them into one category."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    53990\n",
       "3    18869\n",
       "2    18480\n",
       "5    10396\n",
       "7       21\n",
       "4       10\n",
       "Name: admission_type_id, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "onehot_columns.append('admission_type_id')\n",
    "df.replace([6, 8], 5, inplace=True)\n",
    "df['admission_type_id'].value_counts(dropna=False)"
   ]
  },
  {
   "source": [
    "### Discharge disposition (discharge_disposition_id)\n",
    "\n",
    "Integer identifier corresponding to 29 distinct values, for example, discharged to home, expired, and not available.\n",
    "\n",
    "There is no obvious ordering for these so for this reason we will need to encode this as a categorical variable using one-hot encoding.\n",
    "\n",
    "We note that categories \"NULL\", \"not available\" and \"not mapped\" are all effectively unknown and we therefore combine them into one category.There does not appear to be an ordinal "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1     60234\n",
       "5     14194\n",
       "3     13954\n",
       "18     4680\n",
       "2      2128\n",
       "22     1993\n",
       "11     1642\n",
       "4       815\n",
       "7       623\n",
       "23      412\n",
       "13      399\n",
       "14      372\n",
       "28      139\n",
       "15       63\n",
       "24       48\n",
       "9        21\n",
       "17       14\n",
       "16       11\n",
       "19        8\n",
       "10        6\n",
       "27        5\n",
       "12        3\n",
       "20        2\n",
       "Name: discharge_disposition_id, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "onehot_columns.append('discharge_disposition_id')\n",
    "df['discharge_disposition_id'].replace([25, 26], 18, inplace=True)\n",
    "df['discharge_disposition_id'].value_counts(dropna=False)"
   ]
  },
  {
   "source": [
    "### Admission source (admission_source_id)\n",
    "\n",
    "Integer identifier corresponding to 21 distinct values, for example, physician referral, emergency room, and transfer from a hospital\n",
    "\n",
    "There is no obvious ordering for these so for this reason we will need to encode this as a categorical variable using one-hot encoding.\n",
    "\n",
    "We note that categories \"NULL\", \"not available\" and \"not mapped\" are all effectively unknown and we therefore combine them into one category.There does not appear to be an ordinal "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7     57494\n",
       "1     29565\n",
       "17     6781\n",
       "4      3187\n",
       "5      3135\n",
       "2      1104\n",
       "3       187\n",
       "20      161\n",
       "9       125\n",
       "22       12\n",
       "10        8\n",
       "25        2\n",
       "14        2\n",
       "11        2\n",
       "13        1\n",
       "Name: admission_source_id, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "onehot_columns.append('admission_source_id')\n",
    "df['admission_source_id'].replace([17, 21], 15)\n",
    "df['admission_source_id'].value_counts(dropna=False)"
   ]
  },
  {
   "source": [
    "### Time in hospital (time_in_hospital)\n",
    "\n",
    "Integer number of days between admission and discharge"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    101766.000000\n",
       "mean          4.192461\n",
       "std           2.856774\n",
       "min           1.000000\n",
       "25%           2.000000\n",
       "50%           4.000000\n",
       "75%           5.000000\n",
       "max          14.000000\n",
       "Name: time_in_hospital, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df['time_in_hospital'].describe()"
   ]
  },
  {
   "source": [
    "### Payer code (payer_code)\n",
    "\n",
    "Two letter identifier corresponding to 23 distinct values, for example, Blue Cross\\Blue Shield, Medicare, and self-pay\n",
    "\n",
    "This is categorical and not ordinal so it will be one-hot encoded.\n",
    "\n",
    "Note there are 53% unknowns here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unknown    40256\n",
       "MC         32439\n",
       "HM          6274\n",
       "SP          5007\n",
       "BC          4655\n",
       "MD          3532\n",
       "CP          2533\n",
       "UN          2448\n",
       "CM          1937\n",
       "OG          1033\n",
       "PO           592\n",
       "DM           549\n",
       "CH           146\n",
       "WC           135\n",
       "OT            95\n",
       "MP            79\n",
       "SI            55\n",
       "FR             1\n",
       "Name: payer_code, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "onehot_columns.append('payer_code')\n",
    "df['payer_code'].fillna('Unknown', inplace=True)\n",
    "df['payer_code'].value_counts(dropna=False)"
   ]
  },
  {
   "source": [
    "### Medical speciality (medical_specialty)\n",
    "\n",
    "Integer identifier of a specialty of the admitting physician, corresponding to 84 distinct values, for example, cardiology, internal medicine, family\\general practice, and surgeon\n",
    "\n",
    "This is categorical and not ordinal so it will be one-hot encoded.\n",
    "\n",
    "Note 53% of values are unknown here.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unknown                             49949\n",
       "InternalMedicine                    14635\n",
       "Emergency/Trauma                     7565\n",
       "Family/GeneralPractice               7440\n",
       "Cardiology                           5352\n",
       "                                    ...  \n",
       "Psychiatry-Addictive                    1\n",
       "Surgery-PlasticwithinHeadandNeck        1\n",
       "Neurophysiology                         1\n",
       "Pediatrics-InfectiousDiseases           1\n",
       "SportsMedicine                          1\n",
       "Name: medical_specialty, Length: 73, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "onehot_columns.append('medical_specialty')\n",
    "df['medical_specialty'].fillna('Unknown', inplace=True)\n",
    "df['medical_specialty'].value_counts(dropna=False)"
   ]
  },
  {
   "source": [
    "### Number of lab procedures (num_lab_procedures)\n",
    "\n",
    "Number of tests performed during the encounter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    101766.000000\n",
       "mean         43.082080\n",
       "std          19.699706\n",
       "min           1.000000\n",
       "25%          31.000000\n",
       "50%          44.000000\n",
       "75%          57.000000\n",
       "max         132.000000\n",
       "Name: num_lab_procedures, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df['num_lab_procedures'].describe()"
   ]
  },
  {
   "source": [
    "### Number of procedures (num_procedures)\n",
    "\n",
    "Number of procedures (other than lab tests) performed during the encounter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    101766.000000\n",
       "mean          1.291050\n",
       "std           1.581884\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max           5.000000\n",
       "Name: num_procedures, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df['num_procedures'].describe()"
   ]
  },
  {
   "source": [
    "### Number of medications (num_medications)\n",
    "\n",
    "Number of distinct generic names administered during the encounter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    101766.000000\n",
       "mean         15.866999\n",
       "std           8.308746\n",
       "min           1.000000\n",
       "25%          10.000000\n",
       "50%          15.000000\n",
       "75%          20.000000\n",
       "max          81.000000\n",
       "Name: num_medications, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df['num_medications'].describe()"
   ]
  },
  {
   "source": [
    "### Number of outpatient visits (number_outpatient)\n",
    "\n",
    "Number of outpatient visits of the patient in the year preceding the encounter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    101766.000000\n",
       "mean          0.363491\n",
       "std           1.240948\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max          42.000000\n",
       "Name: number_outpatient, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df['number_outpatient'].describe()"
   ]
  },
  {
   "source": [
    "### Number of emergency visits (number_emergency)\n",
    "\n",
    "Number of emergency visits of the patient in the year preceding the encounter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    101766.000000\n",
       "mean          0.195439\n",
       "std           0.915095\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max          76.000000\n",
       "Name: number_emergency, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df['number_emergency'].describe()"
   ]
  },
  {
   "source": [
    "### Number of inpatient visits (number_inpatient)\n",
    "\n",
    "Number of inpatient visits of the patient in the year preceding the encounter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    101766.000000\n",
       "mean          0.626398\n",
       "std           1.223373\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           1.000000\n",
       "max          21.000000\n",
       "Name: number_inpatient, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "df['number_inpatient'].describe()"
   ]
  },
  {
   "source": [
    "### Diagnoses\n",
    "\n",
    "The next three categories contain nearly a thousand distrinct values each. To reduce dimensionality we will categorize the diagnosis codes into categories according to page 5 of the paper. We note that codes 783 and 789 aren't covered and slot those into the Unknown category."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_diagnosis(diag):\n",
    "    diag = str(diag)\n",
    "    if diag == 'Unknown':\n",
    "        return 'Unknown'\n",
    "    elif diag.startswith('E') or diag.startswith('V'):\n",
    "        return 'External'\n",
    "    diag = int(float(diag))\n",
    "    if diag == 250:\n",
    "        return 'Diabetes'\n",
    "    elif (diag >= 390 and diag <= 459) or diag == 785:\n",
    "        return 'Circulatory'\n",
    "    elif (diag >= 460 and diag <= 519) or diag == 786:\n",
    "        return 'Respiratory'\n",
    "    elif (diag >= 520 and diag <= 579) or diag == 787:\n",
    "        return 'Digestive'\n",
    "    elif diag >= 800 and diag <= 999:\n",
    "        return 'Injury'\n",
    "    elif diag >= 710 and diag <= 739:\n",
    "        return 'Musculoskeletal'\n",
    "    elif (diag >= 580 and diag <= 629) or diag == 788:\n",
    "        return 'Genitourinary'\n",
    "    elif diag >= 140 and diag <= 239:\n",
    "        return 'Neoplasms'\n",
    "    elif diag == 780 or diag == 781 or diag == 784 or (diag >= 790 and diag <= 799):\n",
    "        return 'Other'\n",
    "    elif (diag >= 240 and diag <= 279) and diag != 250:\n",
    "        return 'Endocrine'\n",
    "    elif (diag >= 680 and diag <= 709) or diag == 782:\n",
    "        return 'Skin'\n",
    "    elif diag >= 1 and diag <= 139:\n",
    "        return 'Infectious'\n",
    "    elif diag >= 290 and diag <= 319:\n",
    "        return 'Mental'\n",
    "    elif diag >= 280 and diag <= 289:\n",
    "        return 'Blood'\n",
    "    elif diag >= 320 and diag <= 359:\n",
    "        return 'Nervous'\n",
    "    elif diag >= 630 and diag <= 679:\n",
    "        return 'Pregnancy'\n",
    "    elif diag >= 360 and diag <= 389:\n",
    "        return 'Sense'\n",
    "    elif diag >= 740 and diag <= 759:\n",
    "        return 'Congenital'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "source": [
    "### Diagnosis 1 (diag_1)\n",
    "\n",
    "The primary diagnosis (coded as first three digits of ICD9); 848 distinct values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Circulatory        30437\n",
       "Respiratory        14423\n",
       "Digestive           9475\n",
       "Diabetes            8757\n",
       "Injury              6974\n",
       "Genitourinary       5117\n",
       "Musculoskeletal     4957\n",
       "Neoplasms           3433\n",
       "Infectious          2768\n",
       "Endocrine           2702\n",
       "Skin                2614\n",
       "Other               2539\n",
       "Mental              2262\n",
       "External            1645\n",
       "Blood               1103\n",
       "Nervous              947\n",
       "Pregnancy            687\n",
       "Unknown              611\n",
       "Sense                264\n",
       "Congenital            51\n",
       "Name: diag_1, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "onehot_columns.append('diag_1')\n",
    "df['diag_1'].fillna('Unknown', inplace=True)\n",
    "df['diag_1'] = df['diag_1'].apply(categorize_diagnosis)\n",
    "df['diag_1'].value_counts()"
   ]
  },
  {
   "source": [
    "### Diagnosis 2 (diag_2)\n",
    "\n",
    "Secondary diagnosis (coded as first three digits of ICD9); 923 distinct values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Circulatory        31881\n",
       "Diabetes           12794\n",
       "Respiratory        10895\n",
       "Genitourinary       8376\n",
       "Endocrine           8223\n",
       "Digestive           4170\n",
       "Skin                3670\n",
       "Blood               2926\n",
       "Mental              2657\n",
       "Neoplasms           2547\n",
       "External            2536\n",
       "Other               2434\n",
       "Injury              2428\n",
       "Infectious          1931\n",
       "Musculoskeletal     1764\n",
       "Nervous             1126\n",
       "Unknown              725\n",
       "Pregnancy            415\n",
       "Sense                160\n",
       "Congenital           108\n",
       "Name: diag_2, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "onehot_columns.append('diag_2')\n",
    "df['diag_2'].fillna('Unknown', inplace=True)\n",
    "df['diag_2'] = df['diag_2'].apply(categorize_diagnosis)\n",
    "df['diag_2'].value_counts()"
   ]
  },
  {
   "source": [
    "### Diagnosis 3 (diag_3)\n",
    "\n",
    "Additional secondary diagnosis (coded as first three digits of ICD9); 954 distinct values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Circulatory        30306\n",
       "Diabetes           17157\n",
       "Endocrine           9151\n",
       "Respiratory         7358\n",
       "Genitourinary       6680\n",
       "External            5058\n",
       "Digestive           3930\n",
       "Mental              3136\n",
       "Skin                2607\n",
       "Blood               2490\n",
       "Other               2374\n",
       "Injury              1946\n",
       "Musculoskeletal     1915\n",
       "Infectious          1861\n",
       "Neoplasms           1856\n",
       "Unknown             1770\n",
       "Nervous             1503\n",
       "Pregnancy            309\n",
       "Sense                263\n",
       "Congenital            96\n",
       "Name: diag_3, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "onehot_columns.append('diag_3')\n",
    "df['diag_3'].fillna('Unknown', inplace=True)\n",
    "df['diag_3'] = df['diag_3'].apply(categorize_diagnosis)\n",
    "df['diag_3'].value_counts()"
   ]
  },
  {
   "source": [
    "### Number of diagnoses (number_diagnoses)\n",
    "\n",
    "Number of diagnoses entered to the system"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    101766.000000\n",
       "mean          7.009807\n",
       "std           2.128335\n",
       "min           1.000000\n",
       "25%           5.000000\n",
       "50%           7.000000\n",
       "75%           9.000000\n",
       "max          16.000000\n",
       "Name: number_diagnoses, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "df['number_diagnoses'].describe()"
   ]
  },
  {
   "source": [
    "### Glucose serum test result (max_glu_serum)\n",
    "\n",
    "Indicates the range of the result or if the test was not taken. Values: “>200,” “>300,” “normal,” and “none” if not measured.\n",
    "\n",
    "These are ordinal, and we will make the assumption that None, Norm, >200, >300 is a sensible one."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "None    96420\n",
       "Norm     2597\n",
       ">200     1485\n",
       ">300     1264\n",
       "Name: max_glu_serum, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "categorical_mappings.append({\n",
    "    'col': 'max_glu_serum',\n",
    "    'mapping': ordered_mapping(('None', 'Norm', '>200', '>300')),\n",
    "})\n",
    "df['max_glu_serum'].value_counts()"
   ]
  },
  {
   "source": [
    "### A1c test result (A1Cresult)\n",
    "\n",
    "Indicates the range of the result or if the test was not taken. Values: “>8” if the result was greater than 8%, “>7” if the result was greater than 7% but less than 8%, “normal” if the result was less than 7%, and “none” if not measured.\n",
    "\n",
    "The values are ordinal and we will assume None, Norm, >7, >8"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "None    84748\n",
       ">8       8216\n",
       "Norm     4990\n",
       ">7       3812\n",
       "Name: A1Cresult, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "categorical_mappings.append({\n",
    "    'col': 'A1Cresult',\n",
    "    'mapping': ordered_mapping(('None', 'Norm', '>7', '>8')),\n",
    "})\n",
    "df['A1Cresult'].value_counts()"
   ]
  },
  {
   "source": [
    "### Change of medications (change)\n",
    "\n",
    "Indicates if there was a change in diabetic medications (either dosage or generic name). Values: “change” and “no change”\n",
    "\n",
    "No change will be -1, and change will be 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "No    54755\n",
       "Ch    47011\n",
       "Name: change, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "categorical_mappings.append({\n",
    "    'col': 'change',\n",
    "    'mapping': {\n",
    "        'No': -1,\n",
    "        'Ch': 1,\n",
    "    },\n",
    "})\n",
    "df['change'].value_counts()"
   ]
  },
  {
   "source": [
    "### Diabetes medications (diabetesMed)\n",
    "\n",
    "Indicates if there was any diabetic medication prescribed. Values: “yes” and “no”.\n",
    "\n",
    "Yes will be 1 and No will be -1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Yes    78363\n",
       "No     23403\n",
       "Name: diabetesMed, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "categorical_mappings.append({\n",
    "    'col': 'diabetesMed',\n",
    "    'mapping': {\n",
    "        'No': -1,\n",
    "        'Yes': 1,\n",
    "    },\n",
    "})\n",
    "df['diabetesMed'].value_counts()"
   ]
  },
  {
   "source": [
    "### Readmitted (readmitted)\n",
    "\n",
    "Days to inpatient readmission. Values: “<30” if the patient was readmitted in less than 30 days, “>30” if the patient was readmitted in more than 30 days, and “No” for no record of readmission.\n",
    "\n",
    "We assume an order of NO, <30 and >30."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NO     54864\n",
       ">30    35545\n",
       "<30    11357\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "categorical_mappings.append({\n",
    "    'col': 'readmitted',\n",
    "    'mapping': ordered_mapping(('NO', '<30', '>30')),\n",
    "})\n",
    "df['readmitted'].value_counts()"
   ]
  },
  {
   "source": [
    "### 24 features for medications\n",
    "\n",
    "Values: “up” if the dosage was increased during the encounter, “down” if the dosage was decreased, “steady” if the dosage did not change, and “no” if the drug was not prescribed\n",
    "\n",
    "We assume an order of No, Down, Steady and Up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No        81778\n",
      "Steady    18346\n",
      "Up         1067\n",
      "Down        575\n",
      "Name: metformin, dtype: int64\n",
      "No        100227\n",
      "Steady      1384\n",
      "Up           110\n",
      "Down          45\n",
      "Name: repaglinide, dtype: int64\n",
      "No        101063\n",
      "Steady       668\n",
      "Up            24\n",
      "Down          11\n",
      "Name: nateglinide, dtype: int64\n",
      "No        101680\n",
      "Steady        79\n",
      "Up             6\n",
      "Down           1\n",
      "Name: chlorpropamide, dtype: int64\n",
      "No        96575\n",
      "Steady     4670\n",
      "Up          327\n",
      "Down        194\n",
      "Name: glimepiride, dtype: int64\n",
      "No        101765\n",
      "Steady         1\n",
      "Name: acetohexamide, dtype: int64\n",
      "No        89080\n",
      "Steady    11356\n",
      "Up          770\n",
      "Down        560\n",
      "Name: glipizide, dtype: int64\n",
      "No        91116\n",
      "Steady     9274\n",
      "Up          812\n",
      "Down        564\n",
      "Name: glyburide, dtype: int64\n",
      "No        101743\n",
      "Steady        23\n",
      "Name: tolbutamide, dtype: int64\n",
      "No        94438\n",
      "Steady     6976\n",
      "Up          234\n",
      "Down        118\n",
      "Name: pioglitazone, dtype: int64\n",
      "No        95401\n",
      "Steady     6100\n",
      "Up          178\n",
      "Down         87\n",
      "Name: rosiglitazone, dtype: int64\n",
      "No        101458\n",
      "Steady       295\n",
      "Up            10\n",
      "Down           3\n",
      "Name: acarbose, dtype: int64\n",
      "No        101728\n",
      "Steady        31\n",
      "Down           5\n",
      "Up             2\n",
      "Name: miglitol, dtype: int64\n",
      "No        101763\n",
      "Steady         3\n",
      "Name: troglitazone, dtype: int64\n",
      "No        101727\n",
      "Steady        38\n",
      "Up             1\n",
      "Name: tolazamide, dtype: int64\n",
      "No    101766\n",
      "Name: examide, dtype: int64\n",
      "No    101766\n",
      "Name: citoglipton, dtype: int64\n",
      "No        47383\n",
      "Steady    30849\n",
      "Down      12218\n",
      "Up        11316\n",
      "Name: insulin, dtype: int64\n",
      "No        101060\n",
      "Steady       692\n",
      "Up             8\n",
      "Down           6\n",
      "Name: glyburide-metformin, dtype: int64\n",
      "No        101753\n",
      "Steady        13\n",
      "Name: glipizide-metformin, dtype: int64\n",
      "No        101765\n",
      "Steady         1\n",
      "Name: glimepiride-pioglitazone, dtype: int64\n",
      "No        101764\n",
      "Steady         2\n",
      "Name: metformin-rosiglitazone, dtype: int64\n",
      "No        101765\n",
      "Steady         1\n",
      "Name: metformin-pioglitazone, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "medications = [\n",
    " 'metformin',\n",
    " 'repaglinide',\n",
    " 'nateglinide',\n",
    " 'chlorpropamide',\n",
    " 'glimepiride',\n",
    " 'acetohexamide',\n",
    " 'glipizide',\n",
    " 'glyburide',\n",
    " 'tolbutamide',\n",
    " 'pioglitazone',\n",
    " 'rosiglitazone',\n",
    " 'acarbose',\n",
    " 'miglitol',\n",
    " 'troglitazone',\n",
    " 'tolazamide',\n",
    " 'examide',\n",
    " 'citoglipton',\n",
    " 'insulin',\n",
    " 'glyburide-metformin',\n",
    " 'glipizide-metformin',\n",
    " 'glimepiride-pioglitazone',\n",
    " 'metformin-rosiglitazone',\n",
    " 'metformin-pioglitazone',\n",
    "]\n",
    "for medication in medications:\n",
    "    categorical_mappings.append({\n",
    "        'col': medication,\n",
    "        'mapping': ordered_mapping(['No', 'Down', 'Steady', 'Up']),\n",
    "    })\n",
    "    print(df[medication].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = OneHotEncoder(cols=onehot_columns, use_cat_names=True).fit_transform(OrdinalEncoder(cols=[c['col'] for c in categorical_mappings], mapping=categorical_mappings).fit_transform(df))"
   ]
  },
  {
   "source": [
    "## Task 1\n",
    "\n",
    "We will train decision tree, naive bais and knn classifiers as these support multiclass natively. We'll also investigate boosting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_col = lambda d, c : (d[d.columns.difference([c])], d[c])\n",
    "\n",
    "def cv_roc(classifier, X, y, ys=None, show=True):\n",
    "    # Adapted from https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n",
    "    if ys is None:\n",
    "        ys = y\n",
    "    cv = KFold(n_splits=10)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "        classifier.fit(X.iloc[train], ys.iloc[train])\n",
    "        viz = plot_roc_curve(classifier, X.iloc[test], y.iloc[test],\n",
    "                            name='ROC fold {}'.format(i),\n",
    "                            alpha=0.3, lw=1, ax=ax)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "        title=f\"Receiver operating characteristic for {classifier.__class__.__name__}\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return mean_auc\n",
    "\n",
    "def analyse_cm(cm, pr=True):\n",
    "    if not cm:\n",
    "        return {\n",
    "        \"recall\": np.nan,\n",
    "        \"specificity\": np.nan,\n",
    "        \"precision\": np.nan,\n",
    "        \"F\": np.nan,\n",
    "    }\n",
    "    # We will analyse accuracy in terms of negative class (0) vs rest\n",
    "    r = range(1, len(cm))\n",
    "    tp = sum(cm[a][b] for a,b in list(permutations(r, r=2)) + list(zip(r, r)))\n",
    "    fp = sum(cm[0][i] for i in r)\n",
    "    tn = cm[0][0]\n",
    "    fn = sum(cm[i][0] for i in r)\n",
    "    recall = tpr = tp / (tp + fn)\n",
    "    specificity = tnr = tn / (tn + fp)\n",
    "    precision = ppv = tp / (tp + fp)\n",
    "    F = 2 * ((precision * recall) / (precision + recall))\n",
    "    c = {\n",
    "        \"recall\": recall,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"F\": F,\n",
    "    }\n",
    "    if pr:\n",
    "        for k in c:\n",
    "            print(f\"{k}: {c[k]}\")\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = []\n",
    "m_aucs = []\n",
    "scores = []\n",
    "algs = []"
   ]
  },
  {
   "source": [
    "##### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "algs.append(\"DT\")\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    auc_buffer += cv_roc(clf, X, y)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "scores.append(cross_val_score(clf, X, y, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, y, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "source": [
    "##### Naive Bais"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "algs.append(\"NB\")\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    auc_buffer += cv_roc(clf, X, y)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "scores.append(cross_val_score(clf, X, y, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, y, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "source": [
    "##### K Nearest Neighbours"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's first approximate the best value for k"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(*split_col(df, \"readmitted\"), test_size=0.1, random_state=random_state)\n",
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 100\n",
    "min_i = None\n",
    "min_error = None\n",
    "samples = 100\n",
    "for i in range(1, samples):\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1)\n",
    "    clf_knn.fit(X_train, y_train)\n",
    "    pred_i = clf_knn.predict(X_test)\n",
    "    mean_error = np.mean(pred_i != y_test)\n",
    "    if (not min_i and not min_error) or (mean_error < min_error):\n",
    "        min_i = i\n",
    "        min_error = mean_error\n",
    "    error.append(mean_error)\n",
    "print(f\"Min i is {min_i} with mean error of {min_error}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, samples), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=min_i, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "algs.append(f\"kNN({min_i})\")\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    auc_buffer += cv_roc(clf, X, y)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "scores.append(cross_val_score(clf, X, y, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, y, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "source": [
    "Because of the extemely small p-value, we can confidently say these algorithms are significantly different.\n",
    "\n",
    "NB apears to perform best"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Algorithm\", \"Recall\", \"Specificity\", \"Precision\", \"F\", \"m auc\"]\n",
    "rows = []\n",
    "for cm, m_auc, alg in zip(cms, m_aucs, algs):\n",
    "    rows.append([alg, cm['recall'], cm['specificity'], cm['precision'], cm['F'], m_auc])\n",
    "pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "source": [
    "Results are pretty mediocre, let's see if we can do better with boosting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "algs.append(\"BO\")\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    auc_buffer += cv_roc(clf, X, y)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "scores.append(cross_val_score(clf, X, y, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, y, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [list(range(1, 10 + 1)) + [\"mean\", 'stddev', \"p-value\"]]\n",
    "cols = [\"Fold\"]\n",
    "for a, b in combinations(range(0, len(cms)), 2):\n",
    "    sd = scores[a] - scores[b]\n",
    "    cols.append(f\"{algs[a]}-{algs[b]}\")\n",
    "    lists.append(list(sd) + [sd.mean(), sd.std(), ttest_rel(scores[a], scores[b])[1]])\n",
    "pd.DataFrame(zip(*lists), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Algorithm\", \"Recall\", \"Specificity\", \"Precision\", \"F\", \"m auc\"]\n",
    "rows = []\n",
    "for cm, m_auc, alg in zip(cms, m_aucs, algs):\n",
    "    rows.append([alg, cm['recall'], cm['specificity'], cm['precision'], cm['F'], m_auc])\n",
    "pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "source": [
    "##### Comments\n",
    "\n",
    "In general the algorithms perform quite bad.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task 2\n",
    "\n",
    "We're interested to see if we can predict whether a certain medication was administered. Specifically insulin.\n",
    "\n",
    "We'll use 3 models to round out the different families we have yet to explore: SVC, knn and random forest\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = []\n",
    "m_aucs = []\n",
    "scores = []\n",
    "algs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"insulin\")\n",
    "# Turn it into a binary classifier\n",
    "y.replace([2, 3], 1, inplace=True)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=random_state)\n",
    "algs.append(\"RF\")\n",
    "m_auc = cv_roc(clf, X, y)\n",
    "print(m_auc)\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(cross_val_score(clf, X, y, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, y, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=random_state)\n",
    "algs.append(\"SV\")\n",
    "m_auc = cv_roc(clf, X, y)\n",
    "print(m_auc)\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(cross_val_score(clf, X, y, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, y, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=20)\n",
    "algs.append(f\"kNN({min_i})\")\n",
    "m_auc = cv_roc(clf, X, y)\n",
    "print(m_auc)\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(cross_val_score(clf, X, y, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, y, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [list(range(1, 10 + 1)) + [\"mean\", 'stddev', \"p-value\"]]\n",
    "cols = [\"Fold\"]\n",
    "for a, b in combinations(range(0, len(cms)), 2):\n",
    "    sd = scores[a] - scores[b]\n",
    "    cols.append(f\"{algs[a]}-{algs[b]}\")\n",
    "    lists.append(list(sd) + [sd.mean(), sd.std(), ttest_rel(scores[a], scores[b])[1]])\n",
    "pd.DataFrame(zip(*lists), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Algorithm\", \"Recall\", \"Specificity\", \"Precision\", \"F\", \"m auc\"]\n",
    "rows = []\n",
    "for cm, m_auc, alg in zip(cms, m_aucs, algs):\n",
    "    rows.append([alg, cm['recall'], cm['specificity'], cm['precision'], cm['F'], m_auc])\n",
    "pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "source": [
    "#### Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "It appears that RF and SV are not statistically different, with KNN being different."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Part B : Semi-supervised learning & evaluation of results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = []\n",
    "m_aucs = []\n",
    "algs = []\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelPropagation(kernel='knn', n_neighbors=min_i, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "frac = 0.0\n",
    "algs.append(f\"LP({int(frac * 100)})\")\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    ys = y.copy()\n",
    "    ys[ys.sample(frac=frac).index] = -1\n",
    "    auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelPropagation(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.1\n",
    "algs.append(f\"LP({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    ys = y.copy()\n",
    "    ys[ys.sample(frac=frac).index] = -1\n",
    "    auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelPropagation(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.2\n",
    "algs.append(f\"LP({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    ys = y.copy()\n",
    "    ys[ys.sample(frac=frac).index] = -1\n",
    "    auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelPropagation(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.5\n",
    "algs.append(f\"LP({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    ys = y.copy()\n",
    "    ys[ys.sample(frac=frac).index] = -1\n",
    "    auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelPropagation(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.9\n",
    "algs.append(f\"LP({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "try:\n",
    "    for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "        X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "        ys = y.copy()\n",
    "        ys[ys.sample(frac=frac).index] = -1\n",
    "        auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "    m_auc = round(auc_buffer / 3, 3)\n",
    "    print(f\"Mean auc score: {m_auc}\")\n",
    "    m_aucs.append(m_auc)\n",
    "except ValueError:\n",
    "    print(\"Error in algorithm computation\")\n",
    "    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelPropagation(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.95\n",
    "algs.append(f\"LP({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "try:\n",
    "    for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "        X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "        ys = y.copy()\n",
    "        ys[ys.sample(frac=frac).index] = -1\n",
    "        auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "    m_auc = round(auc_buffer / 3, 3)\n",
    "    print(f\"Mean auc score: {m_auc}\")\n",
    "    m_aucs.append(m_auc)\n",
    "except ValueError:\n",
    "    print(\"Error in algorithm computation\")\n",
    "    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Algorithm\", \"Recall\", \"Specificity\", \"Precision\", \"F\", \"m auc\"]\n",
    "rows = []\n",
    "for cm, m_auc, alg in zip(cms, m_aucs, algs):\n",
    "    rows.append([alg, cm['recall'], cm['specificity'], cm['precision'], cm['F'], m_auc])\n",
    "pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [list(range(1, 10 + 1)) + [\"mean\", 'stddev', \"p-value\"]]\n",
    "cols = [\"Fold\"]\n",
    "for a, b in combinations(range(0, len(cms)), 2):\n",
    "    sd = scores[a] - scores[b]\n",
    "    cols.append(f\"{algs[a]}-{algs[b]}\")\n",
    "    lists.append(list(sd) + [sd.mean(), sd.std(), ttest_rel(scores[a], scores[b])[1]])\n",
    "pd.DataFrame(zip(*lists), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelSpreading(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.0\n",
    "algs.append(f\"LS({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "try:\n",
    "    for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "        X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "        ys = y.copy()\n",
    "        ys[ys.sample(frac=frac).index] = -1\n",
    "        auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "    m_auc = round(auc_buffer / 3, 3)\n",
    "    print(f\"Mean auc score: {m_auc}\")\n",
    "    m_aucs.append(m_auc)\n",
    "except ValueError:\n",
    "    print(\"Error in algorithm computation\")\n",
    "    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelSpreading(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.1\n",
    "algs.append(f\"LS({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "try:\n",
    "    for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "        X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "        ys = y.copy()\n",
    "        ys[ys.sample(frac=frac).index] = -1\n",
    "        auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "    m_auc = round(auc_buffer / 3, 3)\n",
    "    print(f\"Mean auc score: {m_auc}\")\n",
    "    m_aucs.append(m_auc)\n",
    "except ValueError:\n",
    "    print(\"Error in algorithm computation\")\n",
    "    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelSpreading(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.2\n",
    "algs.append(f\"LS({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "try:\n",
    "    for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "        X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "        ys = y.copy()\n",
    "        ys[ys.sample(frac=frac).index] = -1\n",
    "        auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "    m_auc = round(auc_buffer / 3, 3)\n",
    "    print(f\"Mean auc score: {m_auc}\")\n",
    "    m_aucs.append(m_auc)\n",
    "except ValueError:\n",
    "    print(\"Error in algorithm computation\")\n",
    "    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelSpreading(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.5\n",
    "algs.append(f\"LS({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "try:\n",
    "    for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "        X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "        ys = y.copy()\n",
    "        ys[ys.sample(frac=frac).index] = -1\n",
    "        auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "    m_auc = round(auc_buffer / 3, 3)\n",
    "    print(f\"Mean auc score: {m_auc}\")\n",
    "    m_aucs.append(m_auc)\n",
    "except ValueError:\n",
    "    print(\"Error in algorithm computation\")\n",
    "    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelSpreading(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.9\n",
    "algs.append(f\"LS({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "try:\n",
    "    for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "        X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "        ys = y.copy()\n",
    "        ys[ys.sample(frac=frac).index] = -1\n",
    "        auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "    m_auc = round(auc_buffer / 3, 3)\n",
    "    print(f\"Mean auc score: {m_auc}\")\n",
    "    m_aucs.append(m_auc)\n",
    "except ValueError:\n",
    "    print(\"Error in algorithm computation\")\n",
    "    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelSpreading(kernel='knn', n_neighbors=min_i, n_jobs=-1)\n",
    "frac = 0.95\n",
    "algs.append(f\"LS({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_buffer = 0\n",
    "try:\n",
    "    for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "        X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "        ys = y.copy()\n",
    "        ys[ys.sample(frac=frac).index] = -1\n",
    "        auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "    m_auc = round(auc_buffer / 3, 3)\n",
    "    print(f\"Mean auc score: {m_auc}\")\n",
    "    m_aucs.append(m_auc)\n",
    "except ValueError:\n",
    "    print(\"Error in algorithm computation\")\n",
    "    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "source": [
    "cms.append(analyse_cm(cm))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semisupervised.StackedAutoEncoderSSL import StackedAutoEncoderClassifier\n",
    "from SAE import StackedAutoEncoder\n",
    "frac = 0.1\n",
    "algs.append(f\"SA({int(frac * 100)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x238 and 30x100)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-f61a398d3881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mauc_buffer\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcv_roc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mm_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_buffer\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Mean auc score: {m_auc}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-09b0da37ef6c>\u001b[0m in \u001b[0;36mcv_roc\u001b[1;34m(classifier, X, y, ys, show)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         viz = plot_roc_curve(classifier, X.iloc[test], y.iloc[test],\n\u001b[0;32m     16\u001b[0m                             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ROC fold {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\semisupervised\\StackedAutoEncoderSSL.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, is_pretrain, validation_data)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                     \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mencoder_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretrain_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[1;31m# ===================backward====================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Oliver\\Desktop\\CSI5155\\Project\\SAE.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mre_x\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mreconstruct\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \"\"\"\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mencoder_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mreconstruct_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mencoder_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstruct_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x238 and 30x100)"
     ]
    }
   ],
   "source": [
    "auc_buffer = 0\n",
    "#try:\n",
    "for pair in ((0, 1), (1, 2), (0, 2)):\n",
    "    X, y = split_col(df[df[\"readmitted\"].isin(pair)], \"readmitted\")\n",
    "    ys = y.copy()\n",
    "    ys[ys.sample(frac=frac).index] = -1\n",
    "    clf = StackedAutoEncoderClassifier(StackedAutoEncoder(X.shape[1], len(ys.unique())), device_name='cpu', verbose=0)\n",
    "    auc_buffer += cv_roc(clf, X, y, ys=ys)\n",
    "m_auc = round(auc_buffer / 3, 3)\n",
    "print(f\"Mean auc score: {m_auc}\")\n",
    "m_aucs.append(m_auc)\n",
    "#except ValueError:\n",
    "#    print(\"Error in algorithm computation\")\n",
    "#    m_aucs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n",
      "Info: Device used : cpu\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a0bfd85c4097>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStackedAutoEncoderClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStackedAutoEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    769\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    770\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 771\u001b[1;33m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[0m\u001b[0;32m    772\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m    773\u001b[0m         for train, test in cv.split(X, y, groups))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\semisupervised\\StackedAutoEncoderSSL.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, is_pretrain, validation_data)\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                     \u001b[0mpatience_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                     print('Info: epoch [{}/{}], loss:{:.4f}'\n\u001b[0;32m    117\u001b[0m                           .format(epoch + 1, self.pretrain_epochs, p_loss))\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "X, y = split_col(df, \"readmitted\")\n",
    "ys = y.copy()\n",
    "ys[ys.sample(frac=frac).index] = -1\n",
    "clf = StackedAutoEncoderClassifier(StackedAutoEncoder(X.shape[1], len(ys.unique())), device_name='cpu', verbose=0)\n",
    "scores.append(cross_val_score(clf, X, ys, cv=10))\n",
    "cm = confusion_matrix(y, cross_val_predict(clf, X, ys, cv=10))\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.append(analyse_cm(cm))"
   ]
  }
 ]
}